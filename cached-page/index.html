
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Cached Page</title>
    <meta name="description" content="">

    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="shortcut icon" href="../favicon.ico">

    <link rel="stylesheet" type="text/css" href="../assets/css/screen.css?v=72c50f038f">
    <link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic%7COpen+Sans:700,400">
    <link rel="stylesheet" type="text/css" href="../assets/css/prism.css?v=72c50f038f">

    <link rel="canonical" href="index.html">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <link rel="amphtml" href="amp/index.html">
    
    <meta property="og:site_name" content="Hello World! I'm Vincent.">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Cached Page">
    <meta property="og:description" content="筆者最近的功課之一是需要撈一個已經下線的網站內容, 所以首先要從網路上的頁面庫存下手 cachedpages; 順帶一提, 撰寫爬蟲撈取資料的人很多, 一種使用 cached page 的方式是因為網站會 ban 掉一些 (惡意?) 造成頻寬問題的連續需求發送端, 所以轉而向 cached page 著手。 Github Source 這裡因為 google 的頁面庫存保留時間過短, 所以實作上僅對 https://archive.org/web/ 做查詢, 用來幫助蒐集仍存留在  cached page server 上的網址有哪些。(當然更辛苦的是針對這些不同時期 mirror 下來的頁面內容做 parsing T.T) python CachedPageSeedFinder.py domain &amp;lt;domain&amp;gt; [--output=&amp;lt;ofname&amp;gt;">
    <meta property="og:url" content="http://captainvincent.github.io/cached-page/">
    <meta property="article:published_time" content="2016-12-24T23:22:40.000Z">
    <meta property="article:modified_time" content="2016-12-25T00:04:43.000Z">
    <meta property="article:tag" content="python">
    <meta property="article:tag" content="crawler">
    <meta property="article:tag" content="cachedpage">
    <meta property="article:tag" content="docopt">
    <meta property="article:tag" content="requests">
    <meta property="article:tag" content="bs4">
    
    <meta property="article:publisher" content="https://www.facebook.com/UndercoverEngineer">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Cached Page">
    <meta name="twitter:description" content="筆者最近的功課之一是需要撈一個已經下線的網站內容, 所以首先要從網路上的頁面庫存下手 cachedpages; 順帶一提, 撰寫爬蟲撈取資料的人很多, 一種使用 cached page 的方式是因為網站會 ban 掉一些 (惡意?) 造成頻寬問題的連續需求發送端, 所以轉而向 cached page 著手。 Github Source 這裡因為 google 的頁面庫存保留時間過短, 所以實作上僅對 https://archive.org/web/ 做查詢, 用來幫助蒐集仍存留在  cached page server 上的網址有哪些。(當然更辛苦的是針對這些不同時期 mirror 下來的頁面內容做 parsing T.T) python CachedPageSeedFinder.py domain &amp;lt;domain&amp;gt; [--output=&amp;lt;ofname&amp;gt;">
    <meta name="twitter:url" content="http://captainvincent.github.io/cached-page/">
    <meta name="twitter:label1" content="Written by">
    <meta name="twitter:data1" content="Captain Vincent">
    <meta name="twitter:label2" content="Filed under">
    <meta name="twitter:data2" content="python, crawler, cachedpage, docopt, requests, bs4">
    
    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Hello World! I&#x27;m Vincent.",
        "logo": "http://captainvincent.github.io/ghost/img/ghosticon.jpg"
    },
    "author": {
        "@type": "Person",
        "name": "Captain Vincent",
        "image": {
            "@type": "ImageObject",
            "url": "http://captainvincent.github.io/content/images/2016/11/--.JPG",
            "width": 889,
            "height": 1080
        },
        "url": "http://captainvincent.github.io/author/vincent/",
        "sameAs": []
    },
    "headline": "Cached Page",
    "url": "http://captainvincent.github.io/cached-page/",
    "datePublished": "2016-12-24T23:22:40.000Z",
    "dateModified": "2016-12-25T00:04:43.000Z",
    "keywords": "python, crawler, cachedpage, docopt, requests, bs4",
    "description": "筆者最近的功課之一是需要撈一個已經下線的網站內容, 所以首先要從網路上的頁面庫存下手 cachedpages; 順帶一提, 撰寫爬蟲撈取資料的人很多, 一種使用 cached page 的方式是因為網站會 ban 掉一些 (惡意?) 造成頻寬問題的連續需求發送端, 所以轉而向 cached page 著手。 Github Source 這裡因為 google 的頁面庫存保留時間過短, 所以實作上僅對 https://archive.org/web/ 做查詢, 用來幫助蒐集仍存留在  cached page server 上的網址有哪些。(當然更辛苦的是針對這些不同時期 mirror 下來的頁面內容做 parsing T.T) python CachedPageSeedFinder.py domain &amp;lt;domain&amp;gt; [--output&#x3D;&amp;lt;ofname&amp;gt;",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "http://captainvincent.github.io"
    }
}
    </script>

    <meta name="generator" content="Ghost 0.11">
    <link rel="alternate" type="application/rss+xml" title="Hello World! I'm Vincent." href="../rss/index.html">
    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-73341093-1', 'auto');
  ga('send', 'pageview');
</script>
</head>
<body class="post-template tag-python tag-crawler tag-cachedpage tag-docopt tag-requests tag-bs4 nav-closed">

    <div class="nav">
    <h3 class="nav-title">Menu</h3>
    <a href="index.html#" class="nav-close">
        <span class="hidden">Close</span>
    </a>
    <ul>
            <li class="nav-blog-home-page" role="presentation"><a href="../">Blog Home Page</a></li>
            <li class="nav-git-book" role="presentation"><a href="https://www.gitbook.com/@captainvincent">Git Book</a></li>
            <li class="nav-aboutme" role="presentation"><a href="https://about.me/CaptainVincent">About.Me</a></li>
    </ul>
        <a class="subscribe-button icon-feed" href="../rss/index.rss">Subscribe</a>
</div>
<span class="nav-cover"></span>


    <div class="site-wrapper">

        


<header class="main-header post-head no-cover">
    <nav class="main-nav  clearfix">
        
            <a class="menu-button icon-menu" href="index.html#"><span class="word">Menu</span></a>
    </nav>
</header>

<main class="content" role="main">
    <article class="post tag-python tag-crawler tag-cachedpage tag-docopt tag-requests tag-bs4">

        <header class="post-header">
            <h1 class="post-title">Cached Page</h1>
            <section class="post-meta">
                <time class="post-date" datetime="2016-12-25">25 December 2016</time>  on <a href="../tag/python/">python</a>, <a href="../tag/crawler/">crawler</a>, <a href="../tag/cachedpage/">cachedpage</a>, <a href="../tag/docopt/">docopt</a>, <a href="../tag/requests/">requests</a>, <a href="../tag/bs4/">bs4</a>
            </section>
        </header>

        <section class="post-content">
            <p>筆者最近的功課之一是需要撈一個已經下線的網站內容, 所以首先要從網路上的頁面庫存下手 <a href="http://www.cachedpages.com/">cachedpages</a>; 順帶一提, 撰寫爬蟲撈取資料的人很多, 一種使用 cached page 的方式是因為網站會 ban 掉一些 (惡意?) 造成頻寬問題的連續需求發送端, 所以轉而向 cached page 著手。</p>

<p><a href="https://github.com/CaptainVincent/CachedPageSeedFinder">Github Source</a></p>

<p>這裡因為 google 的頁面庫存保留時間過短, 所以實作上僅對 <a href="https://archive.org/web/">https://archive.org/web/</a> 做查詢, 用來幫助蒐集仍存留在  cached page server 上的網址有哪些。(當然更辛苦的是針對這些不同時期 mirror 下來的頁面內容做 parsing T.T)</p>

<pre><code class="language-bash">python CachedPageSeedFinder.py domain &lt;domain&gt; [--output=&lt;ofname&gt;] [--input=&lt;dfname&gt;] [--ignore=&lt;list&gt;]  
</code></pre>

<h4 id="options">Options:</h4>

<ul>
<li><code>-h --help</code> Show this screen.</li>
<li><code>--version</code> Show version.</li>
<li><code>--output=&lt;ofname&gt;</code> Output all links to a file</li>
<li><code>--ignore=&lt;list&gt;</code> Ignore url with filter list. Split input use separator ','. ex. --ignore=key1,key2</li>
<li><code>--history</code> Get whole domain link with all history</li>
<li><code>--debugfile=&lt;dfname&gt;</code> Debug only. Test parse link function use an input file.</li>
</ul>

<p>實作的內容很簡單, 先對 cached page 送出查詢後, 將回傳的網頁內容做解析撈出網址即可, 算是很簡易的 crawler, 有興趣的就自行參考看看吧。</p>

<h4 id="pythonmodule">使用到的 python module</h4>

<ul>
<li>docopt 提供命令列解析的工具</li>
<li>requests 用來對 server 發送 request</li>
<li>bs4 (BeautifulSoup) 用來解析 html 的內容</li>
</ul>

<blockquote>
  <p>題外話, 後續要進行解析這些不同時期的庫存頁面工作, 已經改用 scrapy 的框架來實作, 主要是對於大量需要花時間的 io (Internet 連線) 工作, 單一循序的執行過於費時, 透過 scrapy 能同時進行多個非同步的 request 達到改善, 另外在 html 的解析上也改用 lxml (理由是依據 StackOverflow 上 <a href="http://stackoverflow.com/questions/8342335/xpath-vs-dom-vs-beautifulsoup-vs-lxml-vs-other-which-is-the-fastest-approach-to">效能的評估</a>)。</p>
</blockquote>
        </section>

        <footer class="post-footer">


            <figure class="author-image">
                <a class="img" href="../author/vincent/" style="background-image: url(../content/images/2016/11/--.JPG)"><span class="hidden">Captain Vincent's Picture</span></a>
            </figure>

            <section class="author">
                <h4><a href="../author/vincent/">Captain Vincent</a></h4>

                    <p>Read <a href="../author/vincent/">more posts</a> by this author.</p>
                <div class="author-meta">
                    
                    
                </div>
            </section>


            <section class="share">
                <h4>Share this post</h4>
                <a class="icon-twitter" href="https://twitter.com/intent/tweet?text=Cached%20Page&amp;url=http://captainvincent.github.io/cached-page/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                    <span class="hidden">Twitter</span>
                </a>
                <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://captainvincent.github.io/cached-page/" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                    <span class="hidden">Facebook</span>
                </a>
                <a class="icon-google-plus" href="https://plus.google.com/share?url=http://captainvincent.github.io/cached-page/" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
                    <span class="hidden">Google+</span>
                </a>
            </section>


            <div id="disqus_thread"></div>
            <script>
            /**
            * RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
            * LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
            */

            var disqus_config = function () {
                this.page.url = 'http://captainvincent.github.io/cached-page/'; // Replace PAGE_URL with your page's canonical URL variable
                this.page.identifier = 'ghost-47'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
            };

            (function() { // DON'T EDIT BELOW THIS LINE
                var d = document, s = d.createElement('script');

                s.src = '//captainvincent.disqus.com/embed.js';

                s.setAttribute('data-timestamp', +new Date());
                (d.head || d.body).appendChild(s);
            })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>

        </footer>

    </article>
</main>

<aside class="read-next">
    <a class="read-next-story prev no-cover" href="../tradingbot-speech/">
        <section class="post">
            <h2>TradingBot Speech</h2>
            <p>講者 Philipz 鄭淳尹 ＠東吳大學      題外話, 講者在早期參加創業競賽, 當時認識了 VoiceTube 的創辦人詹益維。 Slide Link 目前專業仍是放在資訊背景中的系統架構為主, 提到關於未來技術的 keyword  infrastructure as code 讓大家自己 survey。…</p>
        </section>
    </a>
</aside>



        <footer class="site-footer clearfix">
            <section class="copyright"><a href="../">Hello World! I'm Vincent.</a> © 2016</section>
            <section class="poweredby">Proudly published with <a href="https://ghost.org">Ghost</a></section>
        </footer>

    </div>

    <script type="text/javascript" src="http://code.jquery.com/jquery-1.12.0.min.js"></script>
    
    <script type="text/javascript" src="../assets/js/jquery.fitvids.js?v=72c50f038f"></script>
    <script type="text/javascript" src="../assets/js/index.js?v=72c50f038f"></script>
    <script type="text/javascript" src="../assets/js/prism.js?v=72c50f038f"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [['$','$'], ['\\\\(','\\\\)']],
                processEscapes: true
            }
        });
    </script>
</body>
